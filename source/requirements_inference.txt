# Python 3.14 lock policy: all runtime dependencies are strictly pinned.
# Regenerate lock candidates with:
#   python -m pip install -U pip pip-tools
#   pip-compile --resolver=backtracking --generate-hashes --output-file source/requirements_inference.lock source/requirements_inference.txt

diffusers==0.35.1
einops==0.8.1
k_diffusion==0.1.1.post1
lark==1.2.2
safetensors==0.5.3
tqdm==4.67.1
# Fragile (HF stack): selected alongside accelerate/huggingface_hub to avoid resolver backtracking on Python 3.14.
transformers==4.49.0
spandrel==0.4.1
# Fragile (OpenCV): use first cp314-ready wheel line to avoid local source builds.
opencv-python-headless==4.12.0.88
timm==1.0.11
tomesd==0.1.3
pycloudflared==0.2.0
segment-anything==1.0
geffnet==1.0.2
toml==0.10.2
voluptuous==0.15.2
# Fragile (torch-adjacent): aligned with transformers 4.49.x for stable Trainer/runtime integration.
accelerate==1.2.1
lycoris-lora==2.3.0.dev4
ultralytics==8.3.40
huggingface_hub==0.29.2

# Torch stack is platform/accelerator specific; keep explicit markers to avoid cross-platform conflicts.
# CPU/CUDA (Linux/macOS): install from PyPI or official CUDA index as needed.
# Fragile (torch): pin with torchvision for ABI compatibility.
torch==2.6.0 ; platform_system != "Windows"
# Fragile (torchvision): matched exactly to torch 2.6.0 release family.
torchvision==0.21.0 ; platform_system != "Windows"
# DirectML (Windows): prefer torch-directml instead of upstream CUDA wheels.
# Fragile (DirectML): Windows-only accelerator backend.
torch-directml==0.2.5.dev240914 ; platform_system == "Windows"
